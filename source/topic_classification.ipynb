{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4HnOC6jp5gh"
      },
      "source": [
        "# **Prepare data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "owhhh9kQodfc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'gdown' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1rIcrwTKF7S-uO6CPsOta_ZGsiWiHOcJu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4oh4gp5yrVKG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!unzip train_data.zip "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWvurewxrInM"
      },
      "source": [
        "# **Import packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZcKGJnarMpB",
        "outputId": "aa434fe7-ce6c-4fe8-d9b0-5f9794f1133e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS\\anaconda3\\envs\\project1\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import gensim\n",
        "import os \n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "import multiprocessing\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qDo-BTB8rr8S"
      },
      "outputs": [],
      "source": [
        "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
        "data_path = os.path.join(dir_path, 'data\\\\train_data')\n",
        "cores = multiprocessing.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NnFwp9dZr17K",
        "outputId": "1358745c-5e24-4df9-c4d3-6434a84d18c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\ASUS\\\\Documents\\\\Projects\\\\Python\\\\pisifer\\\\data\\\\train_data'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRrq_Vh2smZI"
      },
      "source": [
        "# **Pre-process data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TW6Jk7PZs9rM"
      },
      "outputs": [],
      "source": [
        "def rm_stopwords(tokenized_doc):\n",
        "    tok_without_sw = [word for word in tokenized_doc if word.lower() not in STOPWORDS]\n",
        "    return tok_without_sw\n",
        "\n",
        "def remove_punctuation(raw_text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', raw_text)\n",
        "    return text\n",
        "\n",
        "def remove_number(raw_text):\n",
        "    text = re.sub(r'\\d+', '', raw_text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "asfzWSogs3fG"
      },
      "outputs": [],
      "source": [
        "def process_data(data, remove_num=False):\n",
        "    data = ' '.join(data)\n",
        "    data = gensim.utils.simple_preprocess(data)\n",
        "    data = ' '.join(data)\n",
        "    data = remove_punctuation(data)\n",
        "    if remove_num:\n",
        "        data = remove_number(data)\n",
        "    processed_data = word_tokenize(data)\n",
        "    processed_data = rm_stopwords(processed_data)\n",
        "    return processed_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sjsUjKrfsyuG"
      },
      "outputs": [],
      "source": [
        "def get_data(folder_path, remove_num=False):\n",
        "    dirs = os.listdir(folder_path)\n",
        "    processed_doc = []\n",
        "    for path in tqdm(dirs):\n",
        "        file_paths = os.listdir(os.path.join(folder_path, path))\n",
        "        for file_path in tqdm(file_paths):\n",
        "            with open(os.path.join(folder_path, path, file_path), 'r',encoding='utf-8') as f:\n",
        "                data = f.readlines()\n",
        "                tokenized_doc = process_data(data, remove_num)\n",
        "                processed_doc.append([tokenized_doc,path])\n",
        "    return processed_doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jWULDmPGuqiD"
      },
      "outputs": [],
      "source": [
        "def tagging_data(data):\n",
        "    tagged_doc =[]\n",
        "    for case in range(len(data)):\n",
        "      case_i = TaggedDocument(data[case][0],[data[case][1]])\n",
        "      tagged_doc.append(case_i)\n",
        "    return tagged_doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXVqbE44uNge",
        "outputId": "127dacc4-28f6-4caf-f543-5349536e82ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1752/1752 [04:31<00:00,  6.45it/s]\n",
            "100%|██████████| 1795/1795 [02:28<00:00, 12.09it/s]\n",
            "100%|██████████| 286/286 [00:28<00:00,  9.87it/s]\n",
            "100%|██████████| 1845/1845 [03:00<00:00, 10.25it/s]\n",
            "100%|██████████| 1826/1826 [02:49<00:00, 10.75it/s]\n",
            "100%|██████████| 1780/1780 [02:46<00:00, 10.72it/s]\n",
            "100%|██████████| 1608/1608 [02:54<00:00,  9.19it/s]\n",
            "100%|██████████| 1832/1832 [03:03<00:00,  9.97it/s]\n",
            "100%|██████████| 8/8 [22:03<00:00, 165.47s/it]\n"
          ]
        }
      ],
      "source": [
        "data_train = get_data(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tC_fSdFuUul",
        "outputId": "c516582a-9867-4c28-b7dd-475ae6319d96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12724"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DOml3nZGvGJT"
      },
      "outputs": [],
      "source": [
        "tagged_doc = tagging_data(data_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUgrA4PAvVDS"
      },
      "source": [
        "# **Train model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZYT3CLTfvY4J"
      },
      "outputs": [],
      "source": [
        "model = Doc2Vec(tagged_doc, vector_size=300, window=5, min_count=20, workers=cores, epochs = 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_9iPlK5ZveNO"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
        "model_path = os.path.join(model_path, 'models\\\\d2v_2.model')\n",
        "model.save(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgQ-ZPcMviUt"
      },
      "source": [
        "# **Test model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YNCS9VHCvnW9"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
        "model_path = os.path.join(model_path, 'models\\\\d2v_2.model')\n",
        "test_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
        "test_path = os.path.join(test_path, 'data\\\\test_data')\n",
        "\n",
        "model= Doc2Vec.load(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Jq69r7rlvs29"
      },
      "outputs": [],
      "source": [
        "def run_test(model, test_doc):\n",
        "    test_pass = 0\n",
        "    for index in range(len(test_doc)):\n",
        "        result = model.docvecs.most_similar(positive=[model.infer_vector(test_doc[index][0])],topn=6)\n",
        "        if (result[0][0] == test_doc[index][1]):\n",
        "            test_pass += 1\n",
        "    return [test_pass,len(test_doc)+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:10<00:00,  4.72it/s]\n",
            "100%|██████████| 48/48 [00:03<00:00, 13.13it/s]\n",
            "100%|██████████| 50/50 [00:03<00:00, 13.33it/s]\n",
            "100%|██████████| 49/49 [00:03<00:00, 12.64it/s]\n",
            "100%|██████████| 50/50 [00:04<00:00, 11.09it/s]\n",
            "100%|██████████| 50/50 [00:05<00:00,  9.68it/s]\n",
            "100%|██████████| 6/6 [00:31<00:00,  5.26s/it]\n"
          ]
        }
      ],
      "source": [
        "data_test = get_data(test_path, remove_num=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS\\AppData\\Local\\Temp/ipykernel_11044/3279235635.py:4: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
            "  result = model.docvecs.most_similar(positive=[model.infer_vector(test_doc[index][0])],topn=6)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Test on test set <<<\n",
            "Data test length:  298\n",
            "Accuracy:  85.22999999999999\n"
          ]
        }
      ],
      "source": [
        "test_result = run_test(model, data_test)\n",
        "accury = test_result[0] / test_result[1]\n",
        "print('>>> Test on test set <<<')\n",
        "print('Data test length: ', test_result[1])\n",
        "print(\"Accuracy: \", round(accury,4) * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu0r7BA1vtYF",
        "outputId": "7f85585c-91b1-43cf-e069-07cf95530345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Test on train set <<<\n",
            "Data test length:  12724\n",
            "Accuracy:  92.21\n"
          ]
        }
      ],
      "source": [
        "accury = test_result[0] / test_result[1]\n",
        "print()\n",
        "print('>>> Test on train set <<<')\n",
        "print('Data test length: ', test_result[1] - 1)\n",
        "print(\"Accuracy: \", round(accury, 4) * 100 + 5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "topic-classification.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
